---
title: "Busca Sistemática de Literatura com R"
author: "Mário O. de Menezes"
format:
  html:
    embed-resources: true
execute: 
  cache: true
---



# Introdução

Realizar uma busca sistemática de literatura científica é normalmente um processo que exige grande esforço, pode durar bastante tempo, consumindo tempo precioso.

<!-- dois artigos que apresentam pacotes para isso:
litsearchr: https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13268
METAGEAR: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12472

Acho que devo falar destes dois (e de outros), criando uma boa documentação do processo,
e apresentando ferramentas que podem se complementar. 

Aqui tem uma sequência de lições sobre como usar o litsearchr. 
https://carpentries-incubator.github.io/lc-litsearchr/

A lição 2 é sobre Revisão Sistemática; parece muito interessante.

Outro pacote, citado nessas lições: synthesisr, para importar, organizar e deduplicar citações bibliográficas de múltiplas fontes.


Um pacote que preciso estudar para incorporar nesses processos é o bibliometrix.
Ele parece ter ferramentas muito importantes para Revisão Sistemática também.
-->

O software estatístico R possui muitas ferramentas apropriadas para se fazer Revisão Sistemática e também Meta-análise. Dentre estas ferramentas temos o pacote `litsearchr`.

Neste tutorial, vamos utilizar vários pacotes para automatizar e facilitar o processo de Revisão Sistemática:

* `litsearchr` -- para uma abordagem automática para identificar os termos de busca para revisões sistemáticas, usando redes de co-ocorrência de palavras chaves.
* `easyPubMed` -- que simplifica o uso da API do PubMed para consulta e extração de dados dos artigos.
* `stopwords` -- base de dados de "Stopwords", do _Stopwords ISO Dataset_ que é a coleção mais abrangente de _stopwords_ para múltiplos idiomas.
* `igraph` -- para análise da rede (este pacote já é uma dependência do pacote `litsearchr`, mas tem muitas outras funções independentes).
* `ggplot2`, `ggraph` e `ggrepel` para gráficos.

# Carregar ou instalar os pacotes

```{r}
#| message: false
#| warning: false

# litsearchr isn't yet on CRAN, need to install from github
if (require(litsearchr)) remotes::install_github("elizagrames/litsearchr", ref = "main")

# Packages to load/install
packages <- c(
  "easyPubMed",
  "litsearchr", "stopwords", "igraph", 
  "ggplot2", "ggraph", "ggrepel"
)

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Load packages
lapply(packages, library, character.only = TRUE)
```


# Consultar PubMed para a literatura relevante

## Consulta simples

Para demonstrar o workflow básico de uma única consulta. Vamos definir uma expressão de busca na variável `term`:

```{r}
term <- '((((((((((("animal*"[All Fields] OR "in vivo"[All Fields] OR "preclinical"[All Fields]) AND "Phototherapy"[All Fields]) OR "Photobiomodulation"[All Fields] OR "Light therapy"[All Fields] OR "LED therapy"[All Fields] OR "Light-emitting diode"[All Fields] OR "Laser therapy"[All Fields]) AND "stem cells"[All Fields]) OR "tissue engineering"[All Fields] OR "cell therapy"[All Fields] OR "cellular therapy"[All Fields] OR "regenerative medicine"[All Fields]) NOT "Review"[Publication Type]) NOT "letter"[Publication Type]) NOT "in vitro techniques"[MeSH Terms]) NOT "clinical trials as topic"[MeSH Terms]) NOT "clinical trial"[Publication Type]) NOT ("veterinary medicine"[MeSH Terms] OR ("veterinary"[All Fields] AND "medicine"[All Fields]) OR "veterinary medicine"[All Fields])) NOT ("veterinary"[MeSH Subheading] OR "veterinary"[All Fields])'
```

Esta expressão de busca foi construída a partir do artigo "Could Light-Based Technologies Improve Stem Cell Therapy for Skin Wounds? A Systematic Review and Meta-Analysis of Preclinical Studies", publicado por Tania M. Yoshimura, Fernanda V. Cabral, Fábio P. Sellera, Lorena Pozzo, Martha S. Ribeiro.

A expressão original citada no artigo é:

```
Animal* OR “in vivo” OR “preclinical” AND “Phototherapy” OR “Photobiomodulation” OR “Light therapy” OR “LED therapy” OR “Light-emitting diode” OR “Laser therapy” AND “stem cells” OR “tissue engineering” OR “cell therapy” OR “cellular therapy” OR “regenerative medicine”
```

Depois foram adicionados as remoções indicados no texto do artigo, resultando na expressão indicada.

Vamos buscar os `ids` na PubMed:

```{r}
pmid_list <- easyPubMed::get_pubmed_ids(term)
```

Agora crianos um `data.frame` com os campos principais:

```{r}
pm_xml <- easyPubMed::fetch_pubmed_data(pmid_list, encoding = "ASCII")
pm_df <- easyPubMed::table_articles_byAuth(pubmed_data = pm_xml,
                                           included_authors = "all",
                                           getKeywords = TRUE, 
                                           max_chars = 500)
```

Vamos ver os 10 primeiros resultados:

```{r}
as.data.frame(lapply(head(pm_df[c("pmid", "doi", "jabbrv", "keywords", "abstract")]), substr, start = 1, stop = 30))

```

# Extraindo os termos dos dados recuperados

```{r}
# Extract terms from title
pm_terms_title <- litsearchr::extract_terms(text = pm_df[,"title"], 
                                            method = "fakerake", min_freq = 3, min_n = 2,
                                            stopwords = stopwords::data_stopwords_stopwordsiso$en)

# Extract terms from keywords
pm_terms_keywords <- litsearchr::extract_terms(keywords = trimws(unlist(strsplit(pm_df[,"keywords"], ";"))), 
                                               method = "tagged", min_freq = 3, min_n = 1, max_n = 5)

# Pool the extracted terms together
pm_terms <- c(pm_terms_title, pm_terms_keywords)
pm_terms <- pm_terms[!duplicated(pm_terms)]
```


# Criação da rede de co-ocorrência

```{r}
# Create Co-Occurrence Network
pm_docs <- paste(pm_df[, "title"], pm_df[, "abstract"]) # we will consider title and abstract of each article to represent the article's "content"
pm_dfm <- litsearchr::create_dfm(elements = pm_docs, features = pm_terms) # document-feature matrix
pm_coocnet <- litsearchr::create_network(pm_dfm, min_studies = 3)

ggraph(pm_coocnet, layout = "stress") +
  coord_fixed() +
  expand_limits(x = c(-3, 3)) +
  geom_edge_link(aes(alpha = weight)) +
  geom_node_point(shape = "circle filled", fill = "white") +
  geom_node_text(aes(label = name), hjust = "outward", check_overlap = TRUE) +
  guides(edge_alpha = "none") +
  theme_void()
```


# Podar a rede baseado na força do nó

## Computar a força do nó

```{r}
# Prune the Network based on node strength
pm_node_strength <- igraph::strength(pm_coocnet)
pm_node_rankstrenght <- data.frame(term = names(pm_node_strength), strength = pm_node_strength, row.names = NULL)
pm_node_rankstrenght$rank <- rank(pm_node_rankstrenght$strength, ties.method = "min")
pm_node_rankstrenght <- pm_node_rankstrenght[order(pm_node_rankstrenght$rank),]

pm_plot_strenght <- 
  ggplot(pm_node_rankstrenght, aes(x = rank, y = strength, label = term)) +
  geom_line(lwd = 0.8) +
  geom_point() +
  ggrepel::geom_text_repel(size = 3, hjust = "right", nudge_y = 3, max.overlaps = 30) +
  theme_bw()
pm_plot_strenght
```


## Podar baseado no critério escolhido

```{r}
# Cumulatively - retain a certain proportion (e.g. 80%) of the total strength of the network of search terms
pm_cutoff_cum <- litsearchr::find_cutoff(pm_coocnet, method = "cumulative", percent = 0.8)
# Changepoints - certain points along the ranking of terms where the strength of the next strongest term is much greater than that of the previous one
pm_cutoff_change <- litsearchr::find_cutoff(pm_coocnet, method = "changepoint", knot_num = 3)

pm_plot_strenght +
  geom_hline(yintercept = pm_cutoff_cum, color = "red", lwd = 0.7, linetype = "longdash", alpha = 0.6) +
  geom_hline(yintercept = pm_cutoff_change, color = "orange", lwd = 0.7, linetype = "dashed", alpha = 0.6)
```


```{r}
pm_cutoff_crit <- pm_cutoff_change[which.min(abs(pm_cutoff_change - pm_cutoff_cum))]  # e.g. nearest cutpoint to cumulative criterion (cumulative produces one value, changepoints may be many)

pm_selected_terms <- litsearchr::get_keywords(litsearchr::reduce_graph(pm_coocnet, pm_cutoff_crit))
```


```{r}
pm_selected_terms
```

Com estes termos, procedemos uma análise manual para excluir aqueles que não interessam e agrupar os restantes; um agrupamento típico na área da saúde é:

* tipo de estudo (_design_);
* tipo de intervenção;
* desordem/sintoma;
* população.

Por exemplo, pode-se excluir termos que indiquem uma população que não é de interesse da pesquisa, ou que restrinjam a população indevidamente.

# Agrupamento manual dos termos

```{r}
#| eval: true

# Só exemplo de como fazer o agrupamento. Não reflete os termos acima.

pm_selected_terms <- pm_selected_terms[-c(18, 19, 20, 32, 22, 25, 30)] # exclude terms

# Manual grouping into clusters - for more rigorous search we will need a combination of OR and AND operators
design <- pm_selected_terms[c(1:3, 11:15, 18, 19, 23, 25)]
intervention <- pm_selected_terms[c(4, 9, 10, 17, 21)]
disorder <- pm_selected_terms[c(5:8, 16, 20, 22, 24)]

# all.equal(length(pm_selected_terms),
#   sum(length(design), length(intervention), length(disorder))
# )  # check that we grouped all terms
      
pm_gruped_selected_terms <- list(  
  design = design,
  intervention = intervention,
  disorder = disorder
)
```

# Automaticamente escreve a nova string de busca

```{r}
#| eval: true

# Write the search
litsearchr::write_search(
  pm_gruped_selected_terms,
  languages = "English",
  exactphrase = TRUE,
  stemming = FALSE,
  closure = "left",
  writesearch = FALSE
)
```

